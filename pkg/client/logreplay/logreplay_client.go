// Code generated by go-swagger; DO NOT EDIT.

package logreplay

// This file was generated by the swagger tool.
// Editing this file might prove futile when you re-run the swagger generate command

import (
	"fmt"

	"github.com/go-openapi/runtime"
	"github.com/go-openapi/strfmt"
)

// New creates a new logreplay API client.
func New(transport runtime.ClientTransport, formats strfmt.Registry) ClientService {
	return &Client{transport: transport, formats: formats}
}

/*
Client for logreplay API
*/
type Client struct {
	transport runtime.ClientTransport
	formats   strfmt.Registry
}

// ClientOption is the option for Client methods
type ClientOption func(*runtime.ClientOperation)

// ClientService is the interface for Client methods
type ClientService interface {
	RunLogReplay(params *RunLogReplayParams, opts ...ClientOption) (*RunLogReplayOK, error)

	SetTransport(transport runtime.ClientTransport)
}

/*
  RunLogReplay runs log replay

  # log-replay

`log-replay` is a service that re-evaluates past decision logs in order to estimate what would change if one of the policies
would be different. `log-replay` is used as an analysis tool to analyze the impact of a policy change.


## API

The service has only one API call to run decision logs re-evaluation:

`POST /v1/logreplay`

### Request

```json
{
    "duration": "10s",
    "max_samples": 5,
    "skip_batches": [
      "boicesr68fj0",
      "boiceye3aeew"
    ],
    "policies": {
      "httpapi/authz": "package httpapi.authz\n # rego policy contents"
    },
    "data_patches": [
      [
        {"op":  "add", "path": "/mydata/value", "value": "something"}
      ]
    ],
    "scope": [
      {"path": "httpapi/authz/allow"}
    ]
}
```

`duration` specifies the total time the analyzer spends on evaluations. If the value is omitted or less than zero then
`DefaultReplayDuration` is used instead. If the value exceeds `MaxReplayDuration`, then it is suppressed.

`max_samples` is the maximum number of representative change samples to return. The value is limited to `MaxSamples` and defaults to `DefaultSamples`.

`skip_batches` is an optional list of batch IDs to skip (obtained from `analyzed_batches` attribute of previous replay run).

`policies` tells `log-replay` which policies to alter in the form of path to payload map.
`log-replay` will re-evaluate any decision log that can be affected by any change in these policies.

`data_patches` is an optional list of atomic JSON-patches to be applied to the data prior to evaluation. The data changes without any policy modifications (empty `policies` map) are accepted. However, at least one of `policies` or `data_patches` must be present.

`decision_patches` is an optional list of atomic JSON-patches to be applied to the decision JSONs as a whole (sic!) before it is replayed. It can be used to compensate values stripped by the mask policy or just inject sample data into the inputs.

`compare_full_results`: do not compare decisions by system-type-dependent significant fields (default: `false`).

`deterministic_policies`: signals that decisions having the same inputs, data and revision always evaluate to the same
result and therefore can be cached (default: `true`).

`scope` allows filtering of analyzed log decisions. It is a list of documents, each can have any of the following attributes:
* `path`:
    * if the decision log path is prefixed by this value, then it will be considered for re-evaluation.
    * if the decision log path is a prefix of this value (for example, scope.path = `policy/allow` and log.path = `scope`), then it is assumed that the decision log result is narrowed to the specified subpath (`/allow` as shown in `policy/allow`).
    * if non of above is true then the decision log will be ignored
* `max_revisions`: only consider last `max_revisions` revisions of the policy (for example, in range `[current - max_revisions .. current]`).
* `max_age`: only consider decision logs that are not older than this parameter. It can be specified either in relative (for example, "30s") or absolute time (RFC3339Nano) formats.
* `min_age`: only consider decision logs that are not newer than this parameter. It can be specified either in relative (for example, "30s") or absolute time (RFC3339Nano) formats.

If `scope` list is empty then any decision log is considered for re-evaluation. The same effect can be achieved with the `[{}]` list.


### Response
```json
{
    "result": {
        "started": "2018-11-26T19:59:28.879307Z",
        "samples": [{
            "labels": {
                "hostname": "8508d25dc62c"
            },
            "type": "agent",
            "name": "16b93fad-c221-4d67-a44f-a1aa90f7a099",
            "agent_id": "16b93fad-c221-4d67-a44f-a1aa90f7a099",
            "timestamp": "2018-11-24T21:43:45.166990877Z",
            "revision": "W3sibCI6Imh0dHBhcGkvYXV0aHoiLCJzIjowfSx7ImwiOiJzeXMvY2F0YWxvZyIsInMiOjEyMjd9XQ",
            "path": "httpapi/authz/allow",
            "input": {
                "method": "GET",
                "path": ["finance", "salary", "donna"],
                "user": "sam"
            },
            "result": false,
            "requested_by": "172.19.0.3:38470",
            "decision_id": "1f6b94cf-f077-4899-8b69-af76e7cdf533",
            "new_result": true
        }],
        "stats": {
            "batches_observed": 203,
            "batches_analyzed": 203,
            "entries_observed": 57311,
            "entries_evaluated": 56263,
            "entries_scheduled": 56263,
            "entries_failed": 0,
            "analysis_errors": 0,
            "results_changed": 2825,
            "batches_downloaded": 203,
            "batches_download_errors": 0,
            "batches_skipped": 2,
            "batches_from_cache": 180,
            "batches_scheduled": 4067
        },
        "analyzed_batches": [
            "boic4gb84ik9",
            "boic6657ynoz",
            "boic7ldstvyy"
        ],
        "duration": 10000201000
    }
}
```

`samples` is the list of representative change samples (up to `max_samples`). Even though the example above found 2875 changed results of past policy decisions, it returned only one sample because all of them were similar (had the same input and data/modules revisions).

All the samples are in regular decision log format with the following two additional attributes:

  * `new_result`: new result of the re-evaluation.
  * `error`: error text when re-evaluation failed (omitted otherwise).

`stats` are various metrics of the analysis, as follows:

  * `batches_scheduled`: number of decision log batches that were scheduled for analysis.
  * `batches_downloaded`: how many decision log batches were downloaded during the analysis (<= `batches_scheduled`).
  * `batches_download_errors`: number of decision batches that could not be downloaded.
  * `batches_skipped`: how many decision log batches were skipped because of the `skip_batches` input or pre-filtration.
  * `batches_from_cache`: how many of downloaded batches were actually taken from the cache (<= `batches_downloaded`).
  * `batches_observed`: number of decision log batches picked by the analyzers (<= `batches_downloaded`).
  * `batches_analyzed`: number of decision log batches fully analyzed (<= `batches_observed`).
  * `entries_observed`: number of decision logs seen in all analyzed batches.
  * `entries_scheduled`: number of decisions scheduled for replay (<= entries_observed).
  * `entries_evaluated`: number of replayed decisions (<= entries_scheduled).
  * `results_changed`: how many decision logs got different result value after re-evaluation (<= `entries_evaluated`).
  * `entries_failed`: how many decision log re-evaluations resulted in error (<= `entries_evaluated`).
  * `analysis_errors`: how many analysis errors happened and potentially caused some decisions to be skipped (<= `entries_observed`).

`duration` is the duration of the analysis in nanoseconds (<= `duration` from the request).

`analyzed_batches`: list of fully analyzed batch IDs (`batches_analyzed` entries).

*/
func (a *Client) RunLogReplay(params *RunLogReplayParams, opts ...ClientOption) (*RunLogReplayOK, error) {
	// TODO: Validate the params before sending
	if params == nil {
		params = NewRunLogReplayParams()
	}
	op := &runtime.ClientOperation{
		ID:                 "RunLogReplay",
		Method:             "POST",
		PathPattern:        "/v1/logreplay",
		ProducesMediaTypes: []string{"application/json"},
		ConsumesMediaTypes: []string{"application/json"},
		Schemes:            []string{"https"},
		Params:             params,
		Reader:             &RunLogReplayReader{formats: a.formats},
		Context:            params.Context,
		Client:             params.HTTPClient,
	}
	for _, opt := range opts {
		opt(op)
	}

	result, err := a.transport.Submit(op)
	if err != nil {
		return nil, err
	}
	success, ok := result.(*RunLogReplayOK)
	if ok {
		return success, nil
	}
	// unexpected success response
	// safeguard: normally, absent a default response, unknown success responses return an error above: so this is a codegen issue
	msg := fmt.Sprintf("unexpected success response for RunLogReplay: API contract not enforced by server. Client expected to get an error, but got: %T", result)
	panic(msg)
}

// SetTransport changes the transport on the client
func (a *Client) SetTransport(transport runtime.ClientTransport) {
	a.transport = transport
}
